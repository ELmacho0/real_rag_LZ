

# 智能知识库问答
> 版本：v1.1  
要点：
>
> + 表格 JSON **弱约束**（只要结构化即可）；
> + **Word 不再强制转 PDF**；页码采用“XML/Section 推算”，允许轻微误差；
> + **Word / PDF 文本 / PDF 扫描 / Excel** 各自独立处理流水线；
> + **所有非文字区域直接送 LLM**：先判类（表格/图表/图片…）再输出“描述 or JSON”；
> + **图表/表格召回 = 向量召回 + 邻近强制召回 + 附表强制召回**；
> + **文件名/Sheet 名纳入独立“标题索引”**用于检索补充；
> + **重排**= 统一加权打分，明确算式与默认权重。
>

---

## 0. 目录
+ [1. 典型用例（从产品使用视角）](#1-典型用例从产品使用视角)
+ [2. 上传后的处理流程（按格式分流）](#2-上传后的处理流程按格式分流)
+ [3. 切片与元数据（补充字段）](#3-切片与元数据补充字段)
+ [4. 向量与索引（含标题索引）](#4-向量与索引含标题索引)
+ [5. 检索与召回策略（含强制召回）](#5-检索与召回策略含强制召回)
+ [6. 融合重排（明确打分函数）](#6-融合重排明确打分函数)
+ [7. 提示词（兼容弱Schema）](#7-提示词兼容弱schema)
+ [8. 配置项新增/变更](#8-配置项新增变更)
+ [9. 验收用例（新增）](#9-验收用例新增)

---

## 1. 典型用例（从产品使用视角）
### 用例 A：首次使用与上传
1. 登录（演示账号）。
2. 进入对话页为空态；点击侧栏“我的知识库”。
3. 拖拽上传 3 个文件：`制度手册.pdf`（文本型）、`绩效模板.xlsx`、`年报.docx`（内含表格与图片）。
4. 每个文件出现卡片：显示“解析中→切片中→向量化→入库中”，伪进度从 5%→50%→88%→99%→100%。
5. 期间可删除某文件（处理中=取消+清理；完成=删除+清理索引）。

### 用例 B：提问并看到来源
1. 回到对话页，输入：“子公司目标考核结果由谁审批？”
2. 系统做**多重改写**，执行多路召回（文本/图片/表格/标题索引），**强制带上下邻近表格**与**附表**。
3. 重排后给出答案，尾部列**来源**（文件名+页/Sheet）。
4. 若无足够证据，返回“无答案”文案，并建议上传/换问法。

### 用例 C：Excel/表格更易被命中
1. 上传 `绩效考核-子公司.xlsx`，Sheet 名如“考核结果”、“目标分解”。
2. 提问“子公司考核结果审批人是谁？”
3. **标题索引**（文件名/Sheet 名向量）帮助命中该文件；
4. 系统把该 Sheet 作为候选证据加入（即便内容向量不强）。

### 用例 D：扫描 PDF 与图表
1. 上传扫描件 `会议纪要（扫描）.pdf`。
2. 系统每页视作图像，**直接送 LLM**：
    - 若是表格 → 输出 JSON；
    - 若是图表/流程图/照片 → 输出摘要文本。
3. 这些“非文字切片”同样被嵌入、召回，并在答案中引用来源页。

---

## 2. 上传后的处理流程（按格式分流）
> 统一入口：判断文件扩展名与 MIME，进入对应流水线。所有流水线共享状态机：  
`UPLOADING → QUEUED → CONVERTING/ANALYZING → CHUNKING → EMBEDDING → INDEXING → READY | FAILED | CANCELED`
>

### 2.1 Word（.docx）流水线
+ **页码推算**：
    1. 读取底层 XML（`word/document.xml`）尝试检测分页标记（`<w:br w:type="page"/>`、`<w:lastRenderedPageBreak/>`）。
    2. 若不可行：按 Section（`sectPr`）的纸张与边距推算分页点（以段落累积高度估算）。

读取文件内容，对其中的文字和非文字区域分别进行处理

+ **文本切片**：按 300–500 字窗口 + 120–150 重叠。为每段切片写入**推算页码**。
+ **非文字元素**：
    - 抽取**内嵌图片**（含表格截图、图表等）。
    - **全部交给 LLM**：先判类（`table/chart/figure/photo/other`），再输出
        * `table` → JSON（弱约束）
        * 其余 → 50–120 字摘要
    - 以“图片切片”形式入库（不参与重叠）。

### 2.2 PDF（文本型）流水线
读取文件内容，对其中的文字和非文字区域分别进行处理

+ **文本抽取**：PyMuPDF；得到每页文本 + 图片对象。
+ **文本切片**：按页→合并→400–800 字切片（带页码），重叠 120–150。
+ **非文字元素**：提取页内图片（或矢量图形截图），**全部交给 LLM** 判类+产出（同 Word）。

### 2.3 PDF（扫描件）流水线
+ **逐页图像**：pdf2image 转为图；
+ 分析每页图像，区分文本和非文本内容，对其中的文字和非文字区域分别进行处理
+ **OCR**：rapidocr_onnxruntime 得到文本块；
+ **非文字区域**：
    - 按版面分块（文本块区域 vs 其余区域）；
    - **文本块**合并做文本切片；
    - **非文字块**截图→**直接送 LLM**判类+产出（表格 JSON / 摘要文本）。
+ **页码**：直接用 PDF 页号。

### 2.4 Excel（.xlsx）流水线
+ **每个 Sheet → 1 个切片**：
    - 正文：字段字典、行数、（可推断的）时间范围、主要指标；可 <400 字。
    - `sheet_preview_json`：前 N=10 行抽样（截断）。
+ **标题索引**：对“文件名 + Sheet 名”各自做嵌入，存入**标题向量索引**（见 §4）。

---

## 3. 切片与元数据（补充字段）
### 3.1 文本类（PDF/Word→PDF）
+ **窗口**：**400–800 字**
+ **重叠**：**120–150 字**（以 130 为基准，向最近句号/换行调整，偏移 ≤ 20 字）。
+ **末片**：可 < 400。
+ **页号**：以**转 PDF**后的页码为准。
+ **页面图片处理**
    - 对面积占比 ≥10% 或分辨率 ≥ 600×600 的图片进行截图。
    - 送入 LLM：先判定“表格/非表格”，再：
        * **表格** → **LLM 转 JSON**（见 §9）并生成简短文字摘要作为切片正文；
        * **非表格** → **LLM 图像摘要**（50–120 字）作为切片正文。
    - 图片/表格切片**不参与**文本重叠。

### 3.2 Excel（每 Sheet = 1 切片）
+ 正文：字段字典（列名/类型/示例）+ 行数 + 可推断的时间范围 + 主要指标。
+ 允许低于 400 字；附 `sheet_preview_json`（前 N=10 行抽样，长值截断 30 字符）

```json
{
  chunk_id,
  doc_id,
  page_from,
  page_to,
  "segment_type": "text|table|chart|figure|photo|excel_sheet",
  "title_guess": "表格/图表/图片的标题或模型猜测",
  "page_estimated": true,              // Word 页码是否为推算
  "appendix_flag": false,              // 是否疑似附表（页尾/目录关键字命中）
  "prev_chunk_id": "…",
  "next_chunk_id": "…"
}
```

**附表识别（弱规则，任一命中即可置 true）**

+ 页码在最后 **10%** 的页面范围；
+ 页内或附近出现“附表/Appendix/附录/表A-1”等关键词；

---

## 4. 向量库与删除
+ **Chroma**：每用户一个 collection：`kb_{user_id}`
+ **Embedding**：Qwen `text-embedding-v4`（dim=2048），metric=`cosine`，HNSW `M=64, ef_construction=256`；查询 `ef=256`
+ `id = chunk_id`；`metadata = §3.2`
+ **删除**：
    - 处理中删除：置 `CANCELED`，中止任务，`delete(where={"doc_id":"..."})` 并清临时文件。
    - 完成后删除：同上。
    - 重建：先按 `doc_id` 清理，再全量入库。

## 5. 向量与索引（含标题索引）
### 5.1 主内容索引
+ 文本切片与非文字切片（表格/图表/图片摘要）的**正文文本**均嵌入（Qwen `text-embedding-v4`）。
+ collection：`kb_{user_id}`；id=`chunk_id`；metadata=§3。

### 5.2 **标题索引**
+ 目的：让**文件名/Sheet 名**在检索时也能被命中，从而把相关 Excel/表格纳入候选。
+ 内容：
    - 每个文件：`title_text = filename` → 嵌入 → 存入 `kb_title_{user_id}`
    - Excel：每个 Sheet：`title_text = f"{filename} / {sheet_name}"` → 嵌入 → 存入同一标题索引
+ 命中后：把对应文件（或 Sheet）的**主内容切片**加入候选（优先级较低，供重排时加分）。

---

## 6. 检索与融合重排
### **6.1 候选池构建（改写 + 多路召回）**
对原问 **Q** 生成 **K=4** 条改写 `R1..RK`，记二者集合为 `Q* = {Q, R1..RK}`。  
对 `Q*` 执行以下多路召回（均设相似度阈值 `MIN_SIM`，命中后做去重，最多保留 **N=30** 个候选切片）：

**主内容向量检索（content index）**

检索范围：`segment_type in {text, table, chart, figure, photo}` 的正文/摘要切片（含 OCR 文本、表格转化成的JSON、figure与photo的摘要文本）。

配额：`Q → top_k=8`；`每个 Ri → top_k=4`；

命中字段：`sim_i`（相似度）、`class_bonus_i`（table=+0.06, chart=+0.03, else 0）。

**标题索引检索（title index）**

检索对象：  
a) **Excel 标题**：`title_text = filename / sheet_name`，命中后加入该 **Sheet 对应切片**；  
b) **图/表标题**：文档内图片/表格的标题或 `title_guess`（由 LLM 解析），命中加入**对应图/表切片**；  
（可选）c) 小节标题（H1/H2）命中加入**该小节首段切片**。

对 `Q*` 检索：每个 query 取 `top_k=2`（阈值过滤后可能更少）。

命中产生的候选，赋：`title_hit_i=1`，并给**基线相似度**`sim_i=0.25`（若无内容相似度）。

**邻近强制召回（neighbor boost）**

对**文本/摘要命中**的前 `Top-N=6` 个候选：

**添加“之后最近的 1 个 table/chart 切片”**（从该切片 `page_to` 向后搜索，跨页允许、跨度上限 `NEIGHBOR_WINDOW_AFTER_PAGES`，默认 1-2 页自行配置）  ；

标注：`neighbor_boost_i=1`，若无相似度则 `sim_i=0.25`。

**附表强制召回（appendix boost）**

对已命中的每个 `doc_id`，若存在 `appendix_flag=true` 的表格：取末尾 `Top-M=2` 加入候选；

标注：`appendix_boost_i=1`；若无相似度则 `sim_i=0.25`。

备注：以上 1)+2)+3)+4) 合并去重后，候选池至多 20 条；不足则按得分补足。

---

### **6.2 **融合重排（新增“聚合 + 交叉重排”）
+ **聚合（merge）：**对同一个 `chunk_id` 的多路命中（原问Q/各改写Ri/标题/邻近/附表），进行归并，聚合出：
    - `sim_max`（向量相似度的最大值，归一到[0,1]）
    - `hit_sources`（去重集合：{vector_Q, vector_Ri, title, neighbor, appendix}）
    - `title_hit_count`、`rewrite_weight_best`（Q=1.0，Ri=0.8，标题/强制=0.6）
    - 其它布尔特征：`neighbor_boost`、`appendix_boost`、`class_bonus`.



+ **交叉重排（rerank）：**将**聚合后的候选（最多 20 个）与融合了原问题Q与其改写W的新改写**按对儿送入重排模型（cross-encoder/LLM-as-reranker），得到 `rel_i ∈ [0,1]`。
    - **未**配置或失败 → 回退：`rel_i = sim_max`（或简单 0.5）。
+ **最终分数（v1.2，可配）****：**

```plain
score_i =
  0.45 * rel_i
+ 0.30 * sim_max
+ 0.10 * rewrite_weight_best
+ 0.06 * (title_hit_count > 0)
+ 0.04 * neighbor_boost
+ 0.02 * appendix_boost
+ 0.03 * class_bonus
+ 0.02 * log1p(|hit_sources|)   # 多源命中略加成
```

+ **无答案规则（同步参考重排）：若 Top-1 满足  
**`rel_1 < MIN_REL`且`sim_max_1 < MIN_SIM`且 无任何 boost（title/neighbor/appendix 均 0）  
→ 返回“无答案”**。**

---

## 7. 提示词（兼容弱Schema）
### 7.1 非文字统一抽取（**判类 + 内容输出**）
> 直接把截图/提取的图片送入 LLM，不做前置算法判别。
>

```plain
PROMPT = (
    """你将接收一张来自文档的图片，请先判断它属于哪一类：\n
    - "table"（可用行列表达的结构化数据）\n
    - "chart"（折线/柱状/饼/面积等可视化）\n
    - "figure"（流程图/架构图/示意图/截图）\n
    - "photo"（照片/插画）\n
    - 若不确定，选最接近的一类。\n\n
    - 识别图片的标题，如果没有识别到标题，则根据内容猜测一个标题\n\n
    - 如果判断判断是table，则将该表格结构化成JSON格式；如果是其他，则转化成对其内容的详细描述\n
    输出格式如下：\n
    {"kind": "table|chart|figure|photo",\n "title": "<识别/推断的标题>",\n  "text": "<单纯的表格的JSON，或其他内容的详细描述>"\n}\n"""
    "要求：严格按照我的输出格式输出，不要输出其他内容！"
)
```

> 解析策略：后端按 `kind` 分流；`table` 若缺字段，尽力补齐；不再做强 Schema 校验，只要键存在、能解析即可。
>

### 7.2 多重改写（同 v1.0，不再赘述）
```plain
你是一个很擅长搜索并在现有资料里找到答案的专家。现在请针对用户提出的问题给出 {K} 个不同检索视角的Query，用于在文档库里召回答案。
● 用户的问题也许在某个表中或某个相关的规范中，也许需要先回答其他问题才能解释用户提出的问题。
● 每条改写尽量不超过 20 个中文字符或 12 个英文词。
● 严格使用分隔符 {DELIM} 连接多条改写；不要输出任何解释或序号。
用户问题：{USER_QUESTION}
仅输出一行文本：Query1{DELIM}Query2{DELIM}...QueryK
```

### 7.3 最终回答系统提示（同 v1.0）
```plain
【用户问题】：
{USER_QUESTION}

【检索改写（隐藏，不回显给用户）】：
{REWRITES_JOINED}

【证据块】（每块以“来源:”起始）：
{EVIDENCE_BLOCKS}

【回答要求】：
- 仅基于证据块回答。证据不足则明确告知无法回答，并建议用户补充资料或换问法。
- 对每个关键结论标注来源，格式：[来源: 文件名 页/Sheet]。
- 重点信息以条目列出，必要时用小表格。
```



---

## 8. 配置项新增/变更
```yaml
# 召回增强
NEIGHBOR_WINDOW_PAGES: 1        # 文本命中切片的前后页范围
NEIGHBOR_PER_SIDE: 1            # 每侧最多取 1 个表格/图表
APPENDIX_TAIL_RATIO: 0.10       # 文档尾部 10% 视为附表候选区
APPENDIX_TOP: 2                 # 每文档最多带入 2 个附表表格

# 标题索引
ENABLE_TITLE_INDEX: true
TITLE_TOPK: 3

# 重排权重
W_SIM: 0.60
W_REWRITE: 0.10
W_TITLE: 0.08
W_NEIGHBOR: 0.08
W_APPENDIX: 0.06
W_CLASS: 0.08
CLASS_BONUS:
  table: 0.06
  chart: 0.03
  figure: 0.00
  photo: 0.00
```

---

## 9. 验收用例（新增）
1. **Word 页码推算**：上传 20 页 docx（含多 Section、分页符），抽检 5 条回答中的页码标注，偏差不超过 ±1 页。
2. **纯文本 PDF + 邻近表格**：正文中提问触发表格答案；即便表格无标题，也能被**邻近强制召回**带入。
3. **扫描 PDF**：含图表与表格的扫描件，LLM 能正确判类并输出“摘要或 JSON”，可被检索使用。
4. **Excel 仅靠标题命中**：问题与文件名/Sheet 名高度相关，但正文向量弱；通过**标题索引**仍能把该 Sheet 带入证据。
5. **附表召回**：文末有“附表 1…”，即便无正文命中，也能作为附表候选加入（`appendix_boost` 生效）。
6. **融合重排**：当文本命中较弱但出现 `neighbor_boost` 或 `title_hit` 时，仍可进入 Top-4；同时无关内容不能被提升。
7. **无答案分歧**：当 Top-1 `sim` < `MIN_SIM` 且无任何 boost 特征，系统返回“无答案”。

---

> 至此，**用例视角 + 分格式流程 + 弱Schema + 强制召回 + 标题索引 + 明确重排** 都齐活了。  
如果你愿意，我可以基于这版 SRS 直接落一个“可运行骨架”（含：索引结构、召回融合、权重配置、UI 卡片状态），你拿去把算法细节替换成你的实现就能跑通端到端。
>

